#!/usr/bin/env python3
#-*- coding: utf-8 -*-

import argparse
import csv
from datetime import datetime as dt
import hashlib
import os
import re
import sys


#============================================================================
# HELPER FUNCTIONS 
#============================================================================

def print_header(subcommand):
    '''Format and print a common header for each subcommand.'''
    title = 'preserve.py {0}'.format(subcommand)
    print('\n' + title)
    print('=' * len(title))


def md5sum(filepath):
    '''For a given file path, return the md5 checksum for that file.'''
    # TODO: if a path to a directory is passed instead of a file path
    # gracefully handle the error.
    with open(filepath, 'rb') as f:
        m = hashlib.md5()
        while True:
            data = f.read(8192)
            if not data:
                break
            m.update(data)
    return m.hexdigest()


def list_files(dir_path):
    '''Return a list of files in a directory tree, pruning out the 
       hidden files & dirs (i.e. those that begin with dot).'''
    result = []
    for root, dirs, files in os.walk(dir_path):
        # prune directories beginning with dot
        dirs[:] = [d for d in dirs if not d.startswith('.')]
        # prune files beginning with dot
        files[:] = [f for f in files if not f.startswith('.')]
        result.extend([os.path.join(root, f) for f in files])
    return result


def read_file(file_path):
    '''Return list of dictionaries representing contents of an inventory 
        file.'''
    with open(file_path, 'r') as f:
        result = [row for row in csv.DictReader(f)]
    return result


def get_metadata(file_path):
    '''Given a path to a file, return a dictionary representing the 
       metadata for that file.'''
    tstamp = int(os.path.getmtime(file_path))
    metadata = {'Directory': os.path.dirname(os.path.abspath(file_path)),
                'Filename': os.path.basename(file_path),
                'MTime': tstamp,
                'Moddate': dt.fromtimestamp(tstamp).strftime(
                    '%Y-%m-%dT%H:%M:%S'),
                'Extension': os.path.splitext(file_path)[1].lstrip('.').upper(),
                'Bytes': os.path.getsize(file_path),
                'MD5': md5sum(file_path)
                }
    return metadata


def get_inventory(path):
    '''Given a path to a file or directory, return list of inventory metadata
       based on reading the inventory, or scanning the directory's files.'''
    if os.path.isfile(path):
        print("  => {0} is a file.".format(path))
        return read_file(path)
    elif os.path.isdir(path):
        print("  => {0} is a directory.".format(path))
        return [get_metadata(f) for f in list_files(path)]
    else:
        print("  => {0} could not be found!".format(path))
        return False


#=== SUBCOMMAND =============================================================
#         NAME: compare
#  DESCRIPTION: check for the presence of files in inventories of various
#               formats (TSM backup, file analyzer, this script)
#============================================================================

def compare(args):
    '''Compare lists of files derived from inventories in various formats,
       including archiving reports from TSM, tab-delimited File Analyzer
       reports, and inventories generated by this script.'''
    print_header(args.func.__name__)
    filelists = {}
    all_files = [args.first] + args.other 
    
    for filepath in all_files:
        result = []
        with open(filepath, 'r') as f:
            rawlines = [line.strip('\n') for line in f.readlines()]
            
            if rawlines[0] == "IBM Tivoli Storage Manager":
                print("Parsing Tivoli output file...")
                p = re.compile(r"([^\\]+) \[Sent\]")
                for line in rawlines:
                    if 'Normal File-->' in line:
                        m = p.search(line)
                        if m:
                            result.append(m.group(1))

            elif "Key" in rawlines[0] or "Filename" in rawlines[0]:
                print("Parsing DPI inventory file... ", end='')
                if '\t' in rawlines[0]:
                    print('tab delimited:')
                    delimiter = '\t'
                else:
                    print('comma delimited:')
                    delimiter = ','
                reader = csv.DictReader(rawlines, delimiter=delimiter)
                filenamecol = "Key" if "Key" in rawlines[0] else "Filename"
                for l in reader:
                    result.append(l[filenamecol])
            
            else:
                print("Unrecognized file type ...")
            
            if result:
                filelists[filepath] = result
                print(" => {0}: {1} files".format(filepath, len(result)))
            else:
                print(" => File {0} has not been parsed.".format(filepath))
    
    all_lists = [set(filelists[filelist]) for filelist in filelists]
    common = set.intersection(*all_lists)
    print("{} values are common to all the supplied files:".format(len(common)))

    for n, filelist in enumerate(filelists):
        unique = set(filelists[filelist]).difference(common)
        print(" => File {0}: {1} values are unique to {2}".format(
                n+1, len(unique), filelist)
            )
        if unique is not None:
            sorted_files = sorted(unique)
            for fnum, fname in enumerate(sorted_files):
                print("     ({0}) {1}".format(fnum+1, fname))
                
    print('')


#=== SUBCOMMAND =============================================================
#         NAME: bytecount
#  DESCRIPTION: count files by extention and sum their sizes
#============================================================================

def bytecount(args):
    '''Sum the bytes in an inventory file or a directory tree, reporting total 
       bytes and number of files broken down by extension.'''
    print_header(args.func.__name__)
    
    print("Loading data from specified path...")
    PATH = args.path
    all_files = get_inventory(PATH)
    
    if not all_files:
        print("ERROR: Could not read inventory data from the specified path.\n")
        sys.exit()
        
    extensions = {}
    totalbytes = 0
    
    for f in all_files:
        totalbytes += int(f['Bytes'])
        ext = f['Extension']
        if ext in extensions:
            extensions[ext] += 1
        else:
            extensions[ext] = 1
            
    exts_summary = [
        "{0}:{1}".format(type, num) for (type, num) in extensions.items()
        ]
    print('{0} bytes for {1} files.'.format(totalbytes, len(all_files)))
    print('({0})'.format(", ".join(exts_summary)))
    
    print('')


#=== SUBCOMMAND =============================================================
#         NAME: inventory
#  DESCRIPTION: Generates a file listing with checksum, file size, timestamp
#============================================================================

def inventory(args):
    '''Create a CSV inventory of file metadata for files in a specified path.'''
    if args.outfile or args.existing:
        print_header(args.func.__name__)
        
    if args.outfile:
        OUTFILE = os.path.abspath(args.outfile)

        if os.path.isfile(OUTFILE):
            print("ERROR: The output file exists.",
                  "Use the -e flag to resume the job.\n")
            sys.exit()
            
        elif os.path.isdir(OUTFILE):
            print("ERROR: The specified output path is a directory.\n")
            sys.exit()

    elif args.existing:
        OUTFILE = os.path.abspath(args.existing)
        
        if not os.path.isfile(OUTFILE):
            print("ERROR: Must specify the path to an existing",
                  "inventory file.\n")
            sys.exit()
            
    else:
        OUTFILE = None

    if os.path.exists(args.path):
        PATH = os.path.abspath(args.path)
    else:
        print("ERROR: The specified search path does not exist.\n")
        sys.exit()
        
    FIELDNAMES = ['Directory', 'Filename', 'Extension', 
                  'Bytes', 'MTime', 'Moddate', 'MD5'
                  ]
    
    # Get a list of all files in the search path.
    all_files = list_files(PATH)
    total = len(all_files)
    files_to_check = all_files  # overriden if outfile specified
    existing_entries = []       # overriden if outfile specified
    count = 0
    
    if OUTFILE:
        print("Checking path: {0}".format(PATH))
        print("Writing to file: {0}".format(OUTFILE))
        
        # If the output file exists, read it and resume the job.
        if os.path.isfile(OUTFILE):
            existing_entries = read_file(OUTFILE)
            all_keys = set().union(*(e.keys() for e in existing_entries))
            
            # if the CSV file conforms to the pattern
            if all_keys == set(FIELDNAMES):
                files_done = [os.path.join(f['Directory'], f['Filename']) \
                    for f in existing_entries]
                    
                # Handle various problem cases
                if files_done == files_to_check:
                    print("Inventory is already complete.\n")
                    sys.exit()
                elif set(files_done).difference(files_to_check):
                    print("ERROR: Existing file contains references to files",
                          "that are not found in the path being inventoried.\n")
                    sys.exit()
                          
                files_to_check = set(all_files).difference(files_done)
            
            # Handle non-conforming CSV file
            else:
                print("ERROR: The specified output file is not a correctly",
                      "formatted inventory CSV.\n")
                sys.exit()
                
        fh = open(OUTFILE, 'w+')
    
    # If no output file has been specified, write to stdout
    else:
        fh = sys.stdout

    writer = csv.DictWriter(fh, fieldnames=FIELDNAMES)
    writer.writeheader()
    # Write the existing portion of the inventory to the output file
    if OUTFILE:
        for entry in existing_entries:
            writer.writerow(entry)
            count += 1

    # check each (remaining) file and generate metadata
    for f in files_to_check:
        metadata = get_metadata(f)
        writer.writerow(metadata)
        count += 1
            
        if OUTFILE:
            # display running counter
            print("Files checked: {0}/{1}".format(count, total), end='\r')

    if OUTFILE:
        fh.close()
        # clear counter
        print('')
        # report successful completion
        print('Inventory complete!')
        print('')


#=== SUBCOMMAND =============================================================
#         NAME: verify
#  DESCRIPTION: verify two sets of files (on disk or as recorded in CSV file) 
#               by comparing their checksums, size, timestamp
#============================================================================

def verify(args):
    '''Verify the identity of two inventories (either stored or created on 
       the fly), by checking for the presence of all files and comparing the 
       checksums of each one.'''
    print_header(args.func.__name__)
    
    print("1. Loading data from 1st path...")
    dict_a = {f['Filename']: f['MD5'] for f in get_inventory(args.first)}
    print("2. Loading data from 2nd path...")
    dict_b = {f['Filename']: f['MD5'] for f in get_inventory(args.second)}
    all_keys = set().union(dict_a.keys(), dict_b.keys())
    not_a = []
    not_b = []
    changed = {}
    verified = 0
    total = len(all_keys)
    
    # Iterate over union of both file inventories
    for n,k in enumerate(all_keys):
        if not k in dict_a:
            not_a.append(k)
        elif not k in dict_b:
            not_b.append(k)
        elif not dict_a[k] == dict_b[k]:
            changed[k] = (dict_a[k], dict_b[k])
        else:
            verified += 1
        print("Checked {0}/{1} files.".format(n+1, total), end='\r')

    # Clear counter
    print('')
    
    # Report success or failure of verification
    if not any([not_a, not_b, changed]):
        print("Success! No differences found.")
    else:
        print("Possible problems were found.")
    
    # Report details of the comparison
    print("  => {0} files are in 1 but not 2.".format(len(not_b)))
    print("  => {0} files are in 2 but not 1.".format(len(not_a)))
    print("  => {0} files show a checksum mismatch.".format(len(changed)))
    print("  => Verified {0}/{1} files.".format(verified, total))
    print('')


#============================================================================
# MAIN LOOP
#============================================================================

def main():
    '''Parse args and set the chosen sub-command as the default function.'''
    # main parser for command line arguments
    parser = argparse.ArgumentParser(
                            description='Digital preservation utilities.'
                            )
                            
    subparsers = parser.add_subparsers(
                            title='subcommands', 
                            description='valid subcommands', 
                            help='-h additional help', 
                            metavar='{bc,inv,comp,ver}',
                            dest='cmd'
                            )
    
    parser.add_argument('-v', '--version', 
                        action='version', 
                        help='Print version number and exit',
                        version='%(prog)s 0.1'
                        )
    
    subparsers.required = True
    
    # parser for the "bytecount" sub-command
    bc_parser = subparsers.add_parser(
                            'bytecount', aliases=['bc'], 
                            help='Count files and sizes in bytes',
                            description='Count files by type and sum bytes.'
                            )
                            
    bc_parser.add_argument( 'path',
                            help='path to search',
                            action='store'
                            )
    
    bc_parser.add_argument( '-r', '--recursive', 
                            help='Recurse through subdirectories',
                            action='store_true'
                            )
                            
    bc_parser.set_defaults(func=bytecount)
    
    
    # parser for the "inventory" sub-command
    inv_parser = subparsers.add_parser(
                            'inventory', aliases=['inv'],
                            help='Create inventory of files with checksums',
                            description='Create dirlisting with file metadata.'
                            )
                            
    inv_parser.add_argument('path',
                            help='path to search',
                            action='store'
                            )
    
    inv_parser.add_argument('-o', '--outfile',
                            help='path to (new) output file',
                            action='store'
                            )

    inv_parser.add_argument('-e', '--existing',
                            help='path to (existing) output file',
                            action='store'
                            )
    
    inv_parser.set_defaults(func=inventory)
    
    
    # parser for the "compare" sub-command
    comp_parser = subparsers.add_parser(
                            'compare', aliases=['comp'],
                            help='Compare two or more inventories',
                            description='Compare contents of file inventories.'
                            )
                            
    comp_parser.add_argument('first', 
                            help='first file'
                            )
                            
    comp_parser.add_argument('other', nargs='+',
                            help='one or more files to compare'
                            )
                            
    comp_parser.set_defaults(func=compare)


    # parser for the "verify" sub-command
    comp_parser = subparsers.add_parser(
                            'verify', aliases=['ver'],
                            help='Verify checksums for two sets of files',
                            description='Verify checksums.'
                            )
                            
    comp_parser.add_argument('first', 
                            help='first file or path'
                            )
                            
    comp_parser.add_argument('second', 
                            help='second file or path'
                            )
                            
    comp_parser.set_defaults(func=verify)

    # parse the args and call the default sub-command function
    args = parser.parse_args()
    args.func(args)


if __name__ == "__main__":
    main()



