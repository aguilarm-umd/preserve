#!/usr/bin/env python3
#-*- coding: utf-8 -*-

import argparse
import csv
from datetime import datetime as dt
import hashlib
import os
import re
import sys


#============================================================================
# HELPER FUNCTIONS 
#============================================================================

def print_header(subcommand):
    '''Format and print a common header for each subcommand.'''
    title = 'preserve.py {0}'.format(subcommand)
    print('\n' + title)
    print('=' * len(title))


def human_readable(bytes):
    '''Return human-readable version of a given number of bytes plus the units,
       rounding to two decimal places for scales in KiB and larger.'''
    orders_mag = [
        'bytes', 'KiB', 'MiB', 'GiB', 'TiB', 'PiB', 'EiB', 'ZiB', 'YiB'
        ]
    for n in range(len(orders_mag)):
        scaled = bytes / (2**(10 * n))
        if scaled >= 0 and scaled < 1024:
            if orders_mag[n] == 'bytes':
                scaled = int(scaled)
            else:
                scaled = round(scaled, 2)
            return(scaled, orders_mag[n])
    return False
    

def list_files(dir_path):
    '''Return a list of files in a directory tree, pruning out the 
       hidden files & dirs (i.e. those that begin with dot).'''
    result = []
    for root, dirs, files in os.walk(dir_path):
        # prune directories beginning with dot
        dirs[:] = [d for d in dirs if not d.startswith('.')]
        # prune files beginning with dot
        files[:] = [f for f in files if not f.startswith('.')]
        result.extend([os.path.join(root, f) for f in files])
    return result


def get_inventory(path):
    '''Given a path to a file or directory, return list of inventory metadata
       based on reading the inventory, or scanning the directory's files.'''
    if os.path.isfile(path):
        print("  => {0} is a file.".format(path))
        with open(path, 'r') as infile:
            dialect = csv.Sniffer().sniff(infile.read(2048))
            infile.seek(0)
            result = []
            for row in csv.DictReader(infile, dialect=dialect):
                a = Asset()
                a.read_inventory(**row)
                result.append(a)
        print("  => read {0} lines from file.".format(len(result)))
        return result
    elif os.path.isdir(path):
        print("  => {0} is a directory.".format(path))
        result = []
        for n, f in enumerate(list_files(path)):
            print("  => found {0} files.".format(n+1), end='\r')
            a = Asset()
            a.analyze_file(f)
            result.append(a)
        print("")
        return result
    else:
        print("  => {0} could not be found!".format(path))
        return False


#============================================================================
# ASSET CLASS
#============================================================================

class Asset(dict):
    def __init__(self):
        pass
        
    def read_inventory(self, **kwargs):
        for key, value in kwargs.items():
            setattr(self, key.lower(), value)
        if not hasattr(self, 'path'):
            self.path = os.path.join(self.directory, self.filename)

    def analyze_file(self, filepath):
        self.path = os.path.abspath(filepath)
        if not os.path.isfile(self.path):
            raise TypeError
        else:
            self.mtime = int(os.path.getmtime(self.path))
            self.directory   = os.path.dirname(self.path)
            self.filename  = os.path.basename(self.path)
            self.moddate = dt.fromtimestamp(self.mtime).strftime(
                                                        '%Y-%m-%dT%H:%M:%S')
            self.extension = os.path.splitext(self.path)[1].lstrip('.').upper()
            self.bytes = os.path.getsize(self.path)
            self.generate_checksums('md5', 'sha1', 'sha256')

    def generate_checksums(self, *args):
        hashes = {}
        if not args: args = ['md5']
        for algorithm in args:
            try:
                hashes[algorithm] = getattr(hashlib, algorithm)()
            except AttributeError:
                pass
        with open(self.path, 'rb') as f:
            while True:
                data = f.read(8192)
                if not data:
                    break
                else:
                    [hash.update(data) for hash in hashes.values()]
        for key, value in hashes.items():
            setattr(self, key, value.hexdigest())


#=== SUBCOMMAND =============================================================
#         NAME: compare
#  DESCRIPTION: check for the presence of files in inventories of various
#               formats (TSM backup, file analyzer, this script)
#============================================================================

def compare(args):
    '''Compare lists of files derived from inventories in various formats,
       including archiving reports from TSM, tab-delimited File Analyzer
       reports, and inventories generated by this script.'''
    print_header(args.func.__name__)
    filelists = {}
    all_files = [args.first] + args.other 
    
    for filepath in all_files:
        result = []
        with open(filepath, 'r') as f:
            rawlines = [line.strip('\n') for line in f.readlines()]
            
            if rawlines[0] == "IBM Tivoli Storage Manager":
                print("Parsing Tivoli output file...")
                p = re.compile(r"([^\\]+) \[Sent\]")
                for line in rawlines:
                    if 'Normal File-->' in line:
                        m = p.search(line)
                        if m:
                            result.append(m.group(1))

            elif "Key" in rawlines[0] or "Filename" in rawlines[0]:
                print("Parsing DPI inventory file... ", end='')
                if '\t' in rawlines[0]:
                    print('tab delimited:')
                    delimiter = '\t'
                else:
                    print('comma delimited:')
                    delimiter = ','
                reader = csv.DictReader(rawlines, delimiter=delimiter)
                filenamecol = "Key" if "Key" in rawlines[0] else "Filename"
                dircol = "Directory"
                for l in reader:
                    result.append(os.path.join(l[filenamecol], l[dircol]))
            
            else:
                print("Unrecognized file type ...")
            
            if result:
                filelists[filepath] = result
                print(" => {0}: {1} files".format(filepath, len(result)))
            else:
                print(" => File {0} has not been parsed.".format(filepath))
    
    all_lists = [set(filelists[filelist]) for filelist in filelists]
    common = set.intersection(*all_lists)
    print(
        "{} values are common to all the supplied files:".format(len(common))
        )

    for n, filelist in enumerate(filelists):
        unique = set(filelists[filelist]).difference(common)
        print(" => File {0}: {1} values are unique to {2}".format(
                n+1, len(unique), filelist)
            )
        if unique is not None:
            sorted_files = sorted(unique)
            for fnum, fname in enumerate(sorted_files):
                print("     ({0}) {1}".format(fnum+1, fname))
                
    print('')


#=== SUBCOMMAND =============================================================
#         NAME: bytecount
#  DESCRIPTION: count files by extention and sum their sizes
#============================================================================

def bytecount(args):
    '''Sum the bytes in an inventory file or a directory tree, reporting total 
       bytes and number of files broken down by extension.'''
    print_header(args.func.__name__)
    
    print("Loading data from specified path...")
    PATH = args.path
    all_files = get_inventory(PATH)
    
    if not all_files:
        print(
            "ERROR: Could not read inventory data from the specified path.\n"
            )
        sys.exit()
        
    extensions = {}
    totalbytes = 0
    
    # Handle different keys in inventory files
    if {'BYTES','EXTENSION'}.issubset([k.upper() for k in all_files[0].keys()]):
        byte_key = 'Bytes'
        ext_key = 'Extension'
    elif {'SIZE','TYPE'}.issubset([k.upper() for k in all_files[0].keys()]):
        byte_key = 'Size'
        ext_key = 'Type'
    else:
        print("ERROR: Cannot interpret this inventory file.\n")
        sys.exit()
    
    # Iterate over the rows of the inventory
    for f in all_files:
        totalbytes += int(f[byte_key])
        ext = f[ext_key]
        if ext in extensions:
            extensions[ext] += 1
        else:
            extensions[ext] = 1
    
    exts_summary = [
        "{0}:{1}".format(type, num) for (type, num) in extensions.items()
        ]
        
    # Convert bytes to human-readable if requested and report results
    if args.human and totalbytes >= 1024:
        count_num, count_units = human_readable(totalbytes)
        print('{0} bytes ({1} {2}) for {3} files.'.format(
            str(totalbytes), count_num, count_units, len(all_files)
            ))       
    else:
        print('{0} bytes for {1} files.'.format(
            str(totalbytes), len(all_files)
            ))
   
    print('({0})'.format(", ".join(exts_summary)))
    print('')


#=== SUBCOMMAND =============================================================
#         NAME: inventory
#  DESCRIPTION: Generates a file listing with checksum, file size, timestamp
#============================================================================

def inventory(args):
    '''Create a CSV inventory of file metadata for files in 
       a specified path.'''
    if args.outfile or args.existing:
        print_header(args.func.__name__)
        
    if args.outfile:
        OUTFILE = os.path.abspath(args.outfile)

        if os.path.isfile(OUTFILE):
            print("ERROR: The output file exists.",
                  "Use the -e flag to resume the job.\n")
            sys.exit()
            
        elif os.path.isdir(OUTFILE):
            print("ERROR: The specified output path is a directory.\n")
            sys.exit()

    elif args.existing:
        OUTFILE = os.path.abspath(args.existing)
        
        if not os.path.isfile(OUTFILE):
            print("ERROR: Must specify the path to an existing",
                  "inventory file.\n")
            sys.exit()
            
    else:
        OUTFILE = None

    if os.path.exists(args.path):
        PATH = os.path.abspath(args.path)
    else:
        print("ERROR: The specified search path does not exist.\n")
        sys.exit()
        
    FIELDNAMES = ['PATH', 'DIRECTORY', 'FILENAME', 
                  'EXTENSION', 'BYTES', 'MTIME', 
                  'MODDATE', 'MD5', 'SHA1', 'SHA256'
                  ]
    
    # Get a list of all files in the search path.
    all_files = list_files(PATH)
    total = len(all_files)
    files_to_check = all_files  # overriden if outfile specified
    existing_entries = []       # overriden if outfile specified
    count = 0
    
    if OUTFILE:
        print("Checking path: {0}".format(PATH))
        print("Writing to file: {0}".format(OUTFILE))
        
        # If the output file exists, read it and resume the job.
        if os.path.isfile(OUTFILE):
            existing_entries = get_inventory(OUTFILE)
            all_keys = set().union(
                *(e.__dict__.keys() for e in existing_entries)
                )
            
            # if the CSV file conforms to the pattern
            if all_keys.issubset([fname.lower() for fname in FIELDNAMES]):
                files_done = [os.path.join(f.directory, f.filename) \
                                for f in existing_entries]
                    
                # Handle various problem cases
                if files_done == files_to_check:
                    print("Inventory is already complete.\n")
                    sys.exit()
                elif set(files_done).difference(files_to_check):
                    print("ERROR: Existing file contains references",
                          "to files that are not found in the path",
                          "being inventoried.\n")
                    sys.exit()
                          
                files_to_check = set(all_files).difference(files_done)
            
            # Handle non-conforming CSV file
            else:
                print("ERROR: The specified output file is not a correctly",
                      "formatted inventory CSV.\n")
                sys.exit()
                
        fh = open(OUTFILE, 'w+')
    
    # If no output file has been specified, write to stdout
    else:
        fh = sys.stdout

    writer = csv.DictWriter(fh, fieldnames=FIELDNAMES)
    writer.writeheader()
    # Write the existing portion of the inventory to the output file
    if OUTFILE:
        for entry in existing_entries:
            writer.writerow({k.upper():v for (k,v) in entry.__dict__.items()})
            count += 1

    # check each (remaining) file and generate metadata
    for f in files_to_check:
        a = Asset()
        a.analyze_file(f)
        writer.writerow({k.upper(): v for k, v in a.__dict__.items()})
        count += 1
            
        if OUTFILE:
            # display running counter
            print("Files checked: {0}/{1}".format(count, total), end='\r')

    if OUTFILE:
        fh.close()
        # clear counter
        print('')
        # report successful completion
        print('Inventory complete!')
        print('')



#=== SUBCOMMAND =============================================================
#         NAME: verify
#  DESCRIPTION: verify two sets of files (on disk or as recorded in CSV file) 
#               by comparing their checksums, size, timestamp
#============================================================================

def verify(args):
    '''Verify the identity of two inventories (either stored or created on 
       the fly), by checking for the presence of all files and comparing the 
       checksums of each one.'''
    print_header(args.func.__name__)
    
    print("1. Loading data from 1st path...")
    dict_a = {f.path: f.md5 for f in get_inventory(args.first)}
    print("2. Loading data from 2nd path...")
    dict_b = {f.path: f.md5 for f in get_inventory(args.second)}
    all_keys = set().union(dict_a.keys(), dict_b.keys())
    not_a = []
    not_b = []
    changed = {}
    verified = 0
    total = len(all_keys)
    
    # Iterate over union of both file inventories
    for n,k in enumerate(all_keys):
        if not k in dict_a:
            not_a.append(k)
        elif not k in dict_b:
            not_b.append(k)
        elif not dict_a[k] == dict_b[k]:
            changed[k] = (dict_a[k], dict_b[k])
        else:
            verified += 1
        print("Checked {0}/{1} files.".format(n+1, total), end='\r')

    # Clear counter
    print('')
    
    # Report success or failure of verification
    if not any([not_a, not_b, changed]):
        print("Success! No differences found.")
    else:
        print("Possible problems were found.")
    
    # Report details of the comparison
    print("  => {0} files are in 1 but not 2.".format(len(not_b)))
    print("  => {0} files are in 2 but not 1.".format(len(not_a)))
    print("  => {0} files show a checksum mismatch.".format(len(changed)))
    for k,v in changed.items():
        print("     - {0}: {1} != {2}".format(k, v[0], v[1]))
    print("  => Verified {0}/{1} files.".format(verified, total))
    print('')


#============================================================================
# MAIN LOOP
#============================================================================

def main():
    '''Parse args and set the chosen sub-command as the default function.'''
    # main parser for command line arguments
    parser = argparse.ArgumentParser(
                            description='Digital preservation utilities.'
                            )
                            
    subparsers = parser.add_subparsers(
                            title='subcommands', 
                            description='valid subcommands', 
                            help='-h additional help', 
                            metavar='{bc,ia,inv,comp,ver}',
                            dest='cmd'
                            )
    
    parser.add_argument('-v', '--version', 
                        action='version', 
                        help='Print version number and exit',
                        version='%(prog)s 0.1'
                        )
    
    subparsers.required = True
    
    # parser for the "bytecount" sub-command
    bc_parser = subparsers.add_parser(
                            'bytecount', aliases=['bc'], 
                            help='Count files and sizes in bytes',
                            description='Count files by type and sum bytes.'
                            )
                            
    bc_parser.add_argument( 'path',
                            help='path to search',
                            action='store'
                            )
    
    bc_parser.add_argument( '-r', '--recursive', 
                            help='Recurse through subdirectories',
                            action='store_true'
                            )
    
    bc_parser.add_argument( '-H', '--human', 
                            help='Human-readable size',
                            action='store_true'
                            )
                            
    bc_parser.set_defaults(func=bytecount)
    
    
    # parser for the "inv_assets" sub-command
    ia_parser = subparsers.add_parser(
                            'inventory', aliases=['inv'],
                            help='Create inventory of files with checksums',
                            description='Create dirlisting with file metadata.'
                            )
                            
    ia_parser.add_argument('path',
                            help='path to search',
                            action='store'
                            )
    
    ia_parser.add_argument('-o', '--outfile',
                            help='path to (new) output file',
                            action='store'
                            )

    ia_parser.add_argument('-e', '--existing',
                            help='path to (existing) output file',
                            action='store'
                            )
    
    ia_parser.set_defaults(func=inventory)
    
    
    # parser for the "compare" sub-command
    comp_parser = subparsers.add_parser(
                            'compare', aliases=['comp'],
                            help='Compare two or more inventories',
                            description='Compare contents of file inventories.'
                            )
                            
    comp_parser.add_argument('first', 
                            help='first file'
                            )
                            
    comp_parser.add_argument('other', nargs='+',
                            help='one or more files to compare'
                            )
                            
    comp_parser.set_defaults(func=compare)


    # parser for the "verify" sub-command
    ver_parser = subparsers.add_parser(
                            'verify', aliases=['ver'],
                            help='Verify checksums for two sets of files',
                            description='Verify checksums.'
                            )
                            
    ver_parser.add_argument('first', 
                            help='first file or path'
                            )
                            
    ver_parser.add_argument('second', 
                            help='second file or path'
                            )
                            
    ver_parser.set_defaults(func=verify)

    # parse the args and call the default sub-command function
    args = parser.parse_args()
    args.func(args)


if __name__ == "__main__":
    main()



